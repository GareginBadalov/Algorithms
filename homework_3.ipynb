{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res\n",
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err\n",
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res\n",
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        print(y_pred)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    return W\n",
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)\n",
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая ошибка 0.02848523152633 с параметрами {'eta': 0.1, 'n_iter': 1500}\n"
     ]
    }
   ],
   "source": [
    "eta_list = [1e-3, 1e-2, 1e-1, 1e-5]\n",
    "count_iter_list = [100, 300, 750, 1000, 1500]\n",
    "\n",
    "best_error = np.inf\n",
    "best_params = {}\n",
    "for eta in eta_list:\n",
    "    for iteration in count_iter_list:\n",
    "        \n",
    "        W = eval_model(X_st, y, iterations=iteration, eta=eta)\n",
    "        if W[2] < best_error:\n",
    "            best_error = W[2]\n",
    "            best_params = {\n",
    "                'eta': eta,\n",
    "                'n_iter': iteration\n",
    "            }\n",
    "print(f'Лучшая ошибка {best_error} с параметрами {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    if res[0] == 0:\n",
    "            res[0] == 0.01\n",
    "    if res[0] == 1:\n",
    "            res[0] == 0.99\n",
    "    if res[1] == 0:\n",
    "            res[1] == 0.01\n",
    "    if res[1] == 1:\n",
    "            res[1] == 0.99\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность принадлежности к 1 классу - \n",
      "[0.32531303 0.32789703 0.88708776 0.01026212 0.75788262 0.56205617\n",
      " 0.95067786 0.13960576 0.32466868 0.88855043]\n",
      "Предсказанные моделью классы - [0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred = sigmoid(z)\n",
    "    return y_pred\n",
    "def calc_pred(W, X):\n",
    "    y_pred = calc_pred_proba(W, X)\n",
    "    y_pred_res = []\n",
    "    for pred in y_pred:\n",
    "        if pred > 0.5:\n",
    "            y_pred_res.append(1)\n",
    "        else:\n",
    "            y_pred_res.append(0)\n",
    "    return y_pred_res\n",
    "W = eval_model(X_st, y, iterations=1500, eta=1e-1)\n",
    "probability_1 = calc_pred_proba(W, X_st)\n",
    "probability_class = calc_pred(W, X_st)\n",
    "print(f\"Вероятность принадлежности к 1 классу - \\n{probability_1}\\nПредсказанные моделью классы - {probability_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
